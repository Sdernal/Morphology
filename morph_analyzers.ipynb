{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Морфология 1\n",
    "\n",
    "Здесь мы познакомимся с двумя мофрологическими анализоторами: pymorphy и mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = u'Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MyStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/mila/anaconda3/envs/my-env/lib/python3.6/site-packages (from pymystem3) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/mila/anaconda3/envs/my-env/lib/python3.6/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/mila/anaconda3/envs/my-env/lib/python3.6/site-packages (from requests->pymystem3) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/mila/anaconda3/envs/my-env/lib/python3.6/site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mila/anaconda3/envs/my-env/lib/python3.6/site-packages (from requests->pymystem3) (2019.9.11)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# поставим модуль если он еще не стоит\n",
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /home/mila/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "# инициализация собственно инициализатора\n",
    "mystem_analyzer = Mystem(entire_input=False, disambiguation=False)\n",
    "# entire_output - сохранение всего входа (напр. пробелов)\n",
    "# disambiguation - снятие омонимии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две основные функции Mystem:\n",
    "- Проводить мофрологический анализ\n",
    "- Приводить начальные формы для слов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_result = mystem_analyzer.analyze(sample_text)\n",
    "mystem_lemmas = mystem_analyzer.lemmatize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка\n",
      "глокая\n",
      "куздра\n",
      "штеко\n",
      "будлануть\n",
      "бокра\n",
      "и\n",
      "курдячить\n",
      "бокренка\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим, что у нас получилось при лемматизации \n",
    "# (да, чтобы вывести юникодные строки на втором питоне приходится так извращаться)\n",
    "print (sample_text)\n",
    "for word in mystem_lemmas:    \n",
    "    print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая\n",
      "ку́здра\n",
      "ште́ко\n",
      "будлану́ла\n",
      "бо́кра\n",
      "и\n",
      "курдя́чит\n",
      "бокрёнка\n"
     ]
    }
   ],
   "source": [
    "# Ну и результат морфологического анализа\n",
    "# выведены всевозможные разборы, чтобы оценить масшатбы\n",
    "for word in mystem_result:\n",
    "    print (word['text'])\n",
    "#     for res in word['analysis']:\n",
    "#         print (repr(res).decode('unicode_escape'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим теперь анализатор со снятием омонимии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_analyzer2 = Mystem(entire_input=False, disambiguation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_result2 = mystem_analyzer2.analyze(sample_text)\n",
    "mystem_lemmas2 = mystem_analyzer2.lemmatize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка\n",
      "глокая глокай\n",
      "куздра куздра\n",
      "штеко штеко\n",
      "будлануть будланул\n",
      "бокра бокра\n",
      "и и\n",
      "курдячить курдячить\n",
      "бокренка бокренок\n"
     ]
    }
   ],
   "source": [
    "print (sample_text)\n",
    "for (word, word2) in zip(mystem_lemmas, mystem_lemmas2):    \n",
    "    print (word, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая\n",
      "ку́здра\n",
      "ште́ко\n",
      "будлану́ла\n",
      "бо́кра\n",
      "и\n",
      "курдя́чит\n",
      "бокрёнка\n"
     ]
    }
   ],
   "source": [
    "for word in mystem_result2:\n",
    "    print (word['text'])\n",
    "#     for res in word['analysis']:\n",
    "#         print '\\t', repr(res).decode('unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемы MyStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "александра\n",
      "иванов\n",
      "пойти\n",
      "в\n",
      "кино\n",
      "александра\n",
      "иванов\n",
      "видеть\n",
      "в\n",
      "кино\n",
      "с\n",
      "кто-то\n",
      "воробей\n",
      "сегодня\n",
      "вставать\n",
      "не\n",
      "с\n",
      "тот\n",
      "нога\n"
     ]
    }
   ],
   "source": [
    "disambiguations = [ 'Александра Иванова пошла в кино',\n",
    "                    'Александра Иванова видели в кино с кем-то',\n",
    "                    'Воробьев сегодня встал не с той ноги']\n",
    "\n",
    "disambiguation_results = []\n",
    "for dis in disambiguations:\n",
    "    disambiguation_results.append(mystem_analyzer2.lemmatize(dis))\n",
    "    \n",
    "for res in disambiguation_results:\n",
    "    for word in res:\n",
    "        print (word,)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "Для того, чтобы наиграться с MyStem, предлагается написать метод, который находит топ n лексем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''александра\n",
    "иванов\n",
    "пойти\n",
    "в\n",
    "кек\n",
    "кек\n",
    "кек\n",
    "кек\n",
    "кино\n",
    "александра\n",
    "иванов\n",
    "видеть\n",
    "в\n",
    "кино\n",
    "с\n",
    "кто-то\n",
    "воробей\n",
    "сегодня\n",
    "вставать\n",
    "не\n",
    "с\n",
    "тот\n",
    "нога\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(text, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param n: number of most common words\n",
    "    :return: list of most common lexemas\n",
    "    '''\n",
    "    mystem_result = mystem_analyzer.analyze(text)\n",
    "    mystem_lemmas = mystem_analyzer.lemmatize(text)\n",
    "    c = Counter()\n",
    "    for word in (mystem_lemmas):\n",
    "        c[word] += 1\n",
    "    top = c.most_common(n)\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('кек', 4), ('александра', 2), ('иванов', 2)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_words(text, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2MB 3.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=714f53d0f0d942b59f3f173b8ce54c1fe598ac4446d3056cc72e3923167ed711\n",
      "  Stored in directory: /home/mila/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "Requirement already up-to-date: pymorphy2-dicts-ru in /home/mila/anaconda3/envs/my-env/lib/python3.6/site-packages (2.4.417127.4579844)\n"
     ]
    }
   ],
   "source": [
    "# установка модуля и словарей\n",
    "!pip install pymorphy2\n",
    "!pip install -U pymorphy2-dicts-ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание анализатора\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = u'Глокая куздра штеко будланула бокра и кудрячит бокренка'\n",
    "# в отличие от mystem работает пословно\n",
    "pymorphy_results = map(lambda x: morph.parse(x), sample_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "гло́кая\n",
      "\t гло́кай NOUN,anim,masc,Name sing,gent 0.3333421575115817\n",
      "\t гло́кай NOUN,anim,masc,Name sing,accs 0.3333421575115817\n",
      "\t гло́кий ADJF femn,sing,nomn 0.30877564526803436\n",
      "\t гло́кий NOUN,anim,femn,Sgtm,Surn sing,nomn 0.021045665122435473\n",
      "\t гло́кать GRND,impf,intr pres 0.0034943745863666442\n",
      "ку́здра\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,nomn 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,gent 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,datv 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,accs 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,ablt 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,loct 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm sing,nomn 0.05\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Geox sing,nomn 0.05\n",
      "ште́ко\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn sing,nomn 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn sing,gent 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn sing,datv 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn sing,accs 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn sing,ablt 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn sing,loct 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn plur,nomn 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn plur,gent 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn plur,datv 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn plur,accs 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn plur,ablt 0.0798025503907856\n",
      "\t ште́ко NOUN,anim,ms-f,Fixd,Surn plur,loct 0.0798025503907856\n",
      "\t ште́ко ADVB 0.021527492115727385\n",
      "\t ште́кий ADJS neut,sing 0.007678595913890023\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,nomn 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,gent 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,datv 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,accs 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,ablt 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,loct 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,nomn 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,gent 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,datv 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,accs 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,ablt 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,loct 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,nomn 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,gent 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,datv 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,accs 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,ablt 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,loct 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,nomn 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,gent 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,datv 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,accs 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,ablt 0.0005484711367064303\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,loct 0.0005484711367064303\n",
      "будлану́ла\n",
      "\t будлану́ть VERB,impf,tran femn,sing,past,indc 0.8463337230666443\n",
      "\t будлану́л NOUN,inan,masc sing,gent 0.11725405044262568\n",
      "\t будлану́лый ADJS femn,sing 0.03490896943377317\n",
      "\t будлану́ла ADVB 0.0015032570569567395\n",
      "бо́кра\n",
      "\t бо́кр NOUN,inan,masc sing,gent 0.45454545454545453\n",
      "\t бо́кра NOUN,inan,femn sing,nomn 0.45454545454545453\n",
      "\t бо́крый ADJS,Qual femn,sing 0.0909090909090909\n",
      "и\n",
      "\t и CONJ 0.998263\n",
      "\t и PRCL 0.000306\n",
      "\t и INTJ 0.000204\n",
      "\t и NOUN,anim,masc,Fixd,Abbr sing,nomn 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr sing,gent 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr sing,datv 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr sing,accs 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr sing,ablt 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr sing,loct 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr plur,nomn 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr plur,gent 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr plur,datv 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr plur,accs 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr plur,ablt 0.000102\n",
      "\t и NOUN,anim,masc,Fixd,Abbr plur,loct 0.000102\n",
      "курдя́чит\n",
      "\t курдя́чить VERB,perf,tran sing,3per,futr,indc 0.9407407407407409\n",
      "\t курдя́читый ADJS,Qual masc,sing 0.0074074074074074086\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,nomn 0.0074074074074074086\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,gent 0.0074074074074074086\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,datv 0.0074074074074074086\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,accs 0.0074074074074074086\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,ablt 0.0074074074074074086\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,loct 0.0074074074074074086\n",
      "\t курдя́читый ADJS masc,sing 0.0074074074074074086\n",
      "бокрёнка\n",
      "\t бокрёнок NOUN,anim,masc sing,gent 0.49999999999999994\n",
      "\t бокрёнок NOUN,anim,masc sing,accs 0.49999999999999994\n"
     ]
    }
   ],
   "source": [
    "# собираем результаты и выводим \n",
    "for word_result in pymorphy_results:\n",
    "    print (word_result[0].word)\n",
    "    for res in word_result:\n",
    "#         print repr(res).decode('unicode_escape')\n",
    "        print ('\\t', res.normal_form, res.tag, res.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от mystem можно получать лексему и склонять слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "градус NOUN\n",
      "градуса NOUN\n",
      "градусу NOUN\n",
      "градус NOUN\n",
      "градусом NOUN\n",
      "градусе NOUN\n",
      "градусы NOUN\n",
      "градусов NOUN\n",
      "градусам NOUN\n",
      "градусы NOUN\n",
      "градусами NOUN\n",
      "градусах NOUN\n"
     ]
    }
   ],
   "source": [
    "bokr = morph.parse(u'градус')[0]\n",
    "for form in bokr.lexeme:\n",
    "    print (form.word, form.tag.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "градусе\n",
      "градус\n",
      "градуса\n",
      "градусов\n"
     ]
    }
   ],
   "source": [
    "print (bokr.inflect({'loct'}).word)\n",
    "print (bokr.make_agree_with_number(1).word)\n",
    "print (bokr.make_agree_with_number(2).word)\n",
    "print (bokr.make_agree_with_number(5).word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание \n",
    "С помощью pymorphy на тексте получить:\n",
    "- Распределение по частям речи\n",
    "- Для части речи вывести топ n лексем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_distribution(text, lexemas=None):\n",
    "    '''\n",
    "    :param: text: input text in russian\n",
    "    :param: lexemas: list of interested pos, if None - all are interesting \n",
    "    :return: dict of pos - probability\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    distribution = {}\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    pymorphy_results = map(lambda x: morph.parse(x), text.split())\n",
    "    tags = []\n",
    "    for word_result in pymorphy_results:\n",
    "        for res in word_result:\n",
    "            tags.append(res.tag.POS)\n",
    "    for tag in tags:\n",
    "        if (not distribution.get(tag)):\n",
    "            distribution[tag] = tags.count(tag)/len(tags)\n",
    "    return distribution\n",
    "\n",
    "def get_top_pos_words(text, pos, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param pos: part of speech \n",
    "    :param n: number of most common words\n",
    "    :return: list of most common lexemas with selected pos\n",
    "    '''\n",
    "    top_lexems = {}\n",
    "    text = text.lower()\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    pymorphy_results = map(lambda x: morph.parse(x), text.split())\n",
    "    lexems = []\n",
    "    for word_result in pymorphy_results:\n",
    "        for res in word_result:\n",
    "            if res.tag.POS == pos:\n",
    "                lexems.append(res.word)\n",
    "    for lexem in lexems:\n",
    "        if (not top_lexems.get(lexem)):\n",
    "            top_lexems[lexem] = lexems.count(lexem)/len(lexems)\n",
    "    \n",
    "    answer = sorted([(top_lexems[lem], lem) for lem in top_lexems], reverse=True)\n",
    "    return [lem[1] for lem in answer[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "александра\n",
      "иванов\n",
      "пойти\n",
      "в\n",
      "кек\n",
      "кек\n",
      "кек\n",
      "кек\n",
      "кино\n",
      "александра\n",
      "иванов\n",
      "видеть\n",
      "в\n",
      "кино\n",
      "с\n",
      "кто-то\n",
      "воробей\n",
      "сегодня\n",
      "вставать\n",
      "не\n",
      "с\n",
      "тот\n",
      "нога\n",
      "\n",
      "{'NOUN': 0.8676470588235294, 'ADJF': 0.04411764705882353, 'INFN': 0.022058823529411766, 'PREP': 0.029411764705882353, 'PRCL': 0.022058823529411766, 'NPRO': 0.007352941176470588, 'ADVB': 0.007352941176470588}\n",
      "['с', 'кино', 'в', 'кек']\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(get_pos_distribution(text))\n",
    "print(get_top_pos_words(text, 'NOUN', 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
