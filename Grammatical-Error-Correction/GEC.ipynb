{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GEC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_SVorW-UVuA"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1aR1WGr_5DcZ-IrAqFIN5gIblpZ0q1tGu?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp4rg3vcf2UI"
      },
      "source": [
        "# Техническая часть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouHsPfxyfznw",
        "outputId": "f4013858-50ca-482b-d772-1e493b8b2d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/DanilDmitriev1999/seq2seq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'seq2seq'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 56 (delta 13), reused 46 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiA5iDLThWYk"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.cuda import FloatTensor, LongTensor\n",
        "\n",
        "from torchtext.data import Field, Example, Dataset, BucketIterator\n",
        "\n",
        "np.random.seed(40)\n",
        "torch.manual_seed(40)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKACL4r3hZeQ"
      },
      "source": [
        "# Данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3rc9azgsM0u"
      },
      "source": [
        "class PrepareData:\n",
        "    def __init__(self, train_path, val_path, batch_size, batch_first=False,\n",
        "                 include_lingths=True, init_token=False):\n",
        "        assert type(batch_first) == bool\n",
        "        assert type(include_lingths) == bool\n",
        "        assert type(init_token) == bool\n",
        "        assert train_path[-3:] == 'txt'\n",
        "\n",
        "        self.train_path = train_path\n",
        "        self.val_path = val_path\n",
        "        self.batch_first = batch_first\n",
        "        self.include_lingths = include_lingths\n",
        "        self.batch_size = batch_size\n",
        "        self.train_path = train_path\n",
        "        self.val_path = val_path\n",
        "\n",
        "        self.BOS_TOKEN = '<s>'\n",
        "        self.EOS_TOKEN = '</s>'\n",
        "        if init_token:\n",
        "            self.source_field = Field(tokenize='spacy', init_token=self.BOS_TOKEN, eos_token=self.EOS_TOKEN,\n",
        "                     lower=True, include_lengths=self.include_lingths, batch_first=self.batch_first)\n",
        "        else:\n",
        "            self.source_field = Field(tokenize='spacy', init_token=None, eos_token=self.EOS_TOKEN,\n",
        "                     lower=True, include_lengths=self.include_lingths, batch_first=self.batch_first)\n",
        "\n",
        "        self.target_field = Field(tokenize='spacy', init_token=self.BOS_TOKEN, eos_token=self.EOS_TOKEN,\n",
        "                             lower=True, batch_first=self.batch_first)\n",
        "        self.fields = [('source', self.source_field), ('target', self.target_field)]\n",
        "\n",
        "    \n",
        "    def read_data(self, path, total):\n",
        "        MAX_TOKENS_COUNT = 23\n",
        "        examples = []\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            for line in tqdm(f, total=total):\n",
        "                line_dict = eval(line)\n",
        "                source_text = self.source_field.preprocess(line_dict['src'])\n",
        "                target_text = self.target_field.preprocess(line_dict['tgt'])\n",
        "                if len(source_text) <= MAX_TOKENS_COUNT and len(target_text) <= MAX_TOKENS_COUNT:\n",
        "                    examples.append(Example.fromlist([source_text, target_text], self.fields))\n",
        "        return examples\n",
        "\n",
        "    def start(self):\n",
        "        train_examples = self.read_data(path=self.train_path, total=34304)\n",
        "        val_examples = self.read_data(path=self.val_path, total=4384)\n",
        "\n",
        "        train_dataset = Dataset(train_examples, self.fields)\n",
        "        test_dataset = Dataset(val_examples, self.fields)\n",
        "\n",
        "        print('Train size =', len(train_dataset))\n",
        "        print('Test size =', len(test_dataset))\n",
        "        print('Example data = ', vars(train_dataset.examples[0]))\n",
        "\n",
        "        self.source_field.build_vocab(train_dataset, min_freq=2)\n",
        "        print('Source vocab size =', len(self.source_field.vocab))\n",
        "\n",
        "        self.target_field.build_vocab(train_dataset, min_freq=2)\n",
        "        print('Target vocab size =', len(self.target_field.vocab))\n",
        "\n",
        "        train_iter, test_iter = BucketIterator.splits(\n",
        "            datasets=(train_dataset, test_dataset),\n",
        "            batch_sizes=(self.batch_size, self.batch_size),\n",
        "            sort_within_batch = True,\n",
        "            sort_key = lambda x : len(x.source),\n",
        "            device=DEVICE,\n",
        "        )\n",
        "        return train_iter, test_iter, self.source_field, self.target_field"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iRLNspz7of1",
        "outputId": "b87e5826-5b29-46be-e969-3544c9bd99b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train_path = 'seq2seq/data/train.txt'\n",
        "val_path = 'seq2seq/data/dev.txt'\n",
        "prepare = PrepareData(train_path, val_path, batch_size=32)\n",
        "train_iter, test_iter, source_field, target_field = prepare.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34304/34304 [00:07<00:00, 4502.94it/s]\n",
            "100%|██████████| 4384/4384 [00:01<00:00, 4207.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size = 25146\n",
            "Test size = 3015\n",
            "Source vocab size = 7567\n",
            "Target vocab size = 7509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iudg4BOwpxL0"
      },
      "source": [
        "# seq2seq with DotAttention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjJx8rwO-XlS"
      },
      "source": [
        "Encoder должен быть подобен символьной сеточке в POS tagging'е: эмбеддить токены и запускать rnn'ку (в данном случае будем пользоваться GRU) и отдавать последнее скрытое состояние.\n",
        "\n",
        "Decoder почти такой же, только еще и предсказывает токены на каждом своем шаге."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xalHeIhEBZv5"
      },
      "source": [
        "Идея Attention (механизма внимания) запоминать все скрытые состояния encoder, а не только последний вектор. Дальше, для вычисления нового слова при генерации найдем сначала представление уже сгенерированного контекста (по которому обычно и генерируется следующее слово).\n",
        "\n",
        "По этому представлению посчитаем оценки полезности состояний энкодера: attention weights. Чем выше вес - тем более полезно состояние. (Можно, кстати, представлять, что в предыдущем варианте мы просто давали всем состояниям кроме последнего вес 0, а последнему - 1).\n",
        "\n",
        "С этими весами состояния энкодера суммируются, и мы получаем взвешенный вектор-представление контекста. Опять вектор?! Но теперь этот вектор получен для конкретного генерируемого слова - это же гораздо лучше, чем пытаться сделать один вектор сразу для всех генерируемых слов. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3AF7EBJBd0Q"
      },
      "source": [
        "From  [Отличный курс по NLP](https://github.com/DanAnastasyev/DeepNLP-Course)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CQpblyWpwYy"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, \n",
        "                           num_layers=num_layers)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs, src_len, hidden=None):\n",
        "        # input = [encoder_seq_len, batch_size]\n",
        "        # hidden = [1, batch_size, rnn_hidden_dim]\n",
        "        emb = self.emb(inputs)\n",
        "        # emb = self.dropout(emb)\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(emb, src_len)\n",
        "        packed_outputs, encoder_hidden = self.rnn(packed_embedded)\n",
        "        encoder_output, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "        return encoder_output, encoder_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wQWeS8ZBfKV"
      },
      "source": [
        "В общем случае, attention работает так: пусть у нас есть набор скрытых состояний $\\mathbf{s}_1, \\ldots, \\mathbf{s}_m$ - представлений слов из исходного языка, полученных с помощью энкодера. И есть некоторое текущее скрытое состояние $\\mathbf{h}_i$ - скажем, представление, используемое для предсказания слова на нужном нам языке.\n",
        "\n",
        "Тогда с помощью аттеншена мы можем получить взвешенное представление контекста $\\mathbf{s}_1, \\ldots, \\mathbf{s}_m$ - вектор $\\mathbf{c}_i$:\n",
        "$$\n",
        "\\begin{align}\\begin{split}\n",
        "\\mathbf{c}_i &= \\sum\\limits_j a_{ij}\\mathbf{s}_j\\\\\n",
        "\\mathbf{a}_{ij} &= \\text{softmax}(f_{att}(\\mathbf{h}_i, \\mathbf{s}_j))\n",
        "\\end{split}\\end{align}\n",
        "$$\n",
        "\n",
        "$f_{att}$ - функция, которая говорит, насколько хорошо $\\mathbf{h}_i$ и $\\mathbf{s}_j$ подходят друг другу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHn0Bu8mBlX7"
      },
      "source": [
        "Я рассматривал только dotattention, чтобы потом было проще с transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_JTId3Vz5NN"
      },
      "source": [
        "- Dot attention:\n",
        "$$f_{att}(\\mathbf{h}_i, \\mathbf{s}_j) = \\mathbf{h}_i^\\top \\mathbf{s}_j$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC88Nm4e7JbU"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, attn_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_0 = nn.Linear(2 * rnn_hidden_dim, rnn_hidden_dim)\n",
        "\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(input_size=emb_dim + rnn_hidden_dim, hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self.out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    @staticmethod\n",
        "    def dot_attention(query, key, value, mask):\n",
        "        # query = [batch_size, query_size]\n",
        "        # key = [encoder_seq_len, batch_size, key_size]\n",
        "        # value = [encoder_seq_len, batch_size, key_size]\n",
        "        # mask = [encoder_seq_len, batch_size]\n",
        "        \n",
        "        f_att = torch.matmul(query, key.transpose(-2, -1))\n",
        "        f_att.data.masked_fill_(mask.unsqueeze(-2), -float('inf'))\n",
        "        weights = F.softmax(f_att, -1)\n",
        "        output = torch.matmul(weights, value)\n",
        "        return output.sum(0), weights\n",
        "\n",
        "    def forward(self, inputs, encoder_output, encoder_mask, encoder_hidden, output=None, hidden=None):\n",
        "        # inputs = [decoder_seq_len, batch_size]\n",
        "        # encoder_output = [encoder_seq_len, batch_size, rnn_hidden_dim]\n",
        "        # encoder_mask = [encoder_seq_len, batch_size]\n",
        "        # hidden = [1, batch_size, rnn_hidden_dim]\n",
        "        if output is None:\n",
        "            output = self.fc_0(encoder_output)\n",
        "\n",
        "        embs = self.emb(inputs)\n",
        "        # embs = self.dropout(embs)\n",
        "        outputs, attentions = [], []\n",
        "\n",
        "        for i in range(embs.shape[0]):\n",
        "            context, weights = self.dot_attention(query=hidden, key=output, value=output, mask=encoder_mask)\n",
        "            context = context.unsqueeze(0)\n",
        "            rnn_input = torch.cat((embs[i: i+1], context), -1)\n",
        "            out, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "            outputs.append(out)\n",
        "            attentions.append(weights)\n",
        "\n",
        "        out = torch.cat(outputs)\n",
        "        attention = torch.cat(attentions)\n",
        "        return self.out(out), hidden, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz14q9j47M63"
      },
      "source": [
        "class Seq2seq_with_attention(nn.Module):\n",
        "    def __init__(self, source_vocab_size, target_vocab_size, emb_dim=64, rnn_hidden_dim=128, \n",
        "                 attn_dim=128, num_layers=1):\n",
        "\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(source_vocab_size, emb_dim, rnn_hidden_dim, num_layers)\n",
        "        self.decoder = Decoder(target_vocab_size, emb_dim, rnn_hidden_dim, attn_dim, num_layers)\n",
        "\n",
        "    def forward(self, source_inputs, source_len, target_inputs):\n",
        "        encoder_mask = source_inputs == 1.  # добавим маску, чтобы игнорировать паддинги\n",
        "        encoder_output, encoder_hidden = self.encoder(source_inputs, source_len)\n",
        "\n",
        "        output = encoder_output\n",
        "        hidden = encoder_hidden\n",
        "\n",
        "        return self.decoder(target_inputs, encoder_output, encoder_mask, encoder_hidden, output, hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTIQ-AKh7Pue",
        "outputId": "55adf179-e76f-43a6-acf0-3eb65f237de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from seq2seq.utils.utilsSeq2seq import *\n",
        "\n",
        "model = Seq2seq_with_attention(source_vocab_size=len(source_field.vocab),\n",
        "                               target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=35, val_iter=test_iter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 35] Train: Loss = 5.35208, PPX = 211.05: 100%|██████████| 786/786 [00:22<00:00, 35.27it/s]\n",
            "[1 / 35]   Val: Loss = 4.72202, PPX = 112.40: 100%|██████████| 95/95 [00:01<00:00, 76.79it/s]\n",
            "[2 / 35] Train: Loss = 5.03307, PPX = 153.40:   1%|          | 4/786 [00:00<00:43, 17.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 1.71\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 / 35] Train: Loss = 4.44834, PPX = 85.48: 100%|██████████| 786/786 [00:22<00:00, 35.36it/s]\n",
            "[2 / 35]   Val: Loss = 4.27227, PPX = 71.68: 100%|██████████| 95/95 [00:01<00:00, 76.91it/s]\n",
            "[3 / 35] Train: Loss = 2.14084, PPX = 8.51:   1%|          | 6/786 [00:00<00:26, 29.01it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 3.27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[3 / 35] Train: Loss = 4.00010, PPX = 54.60: 100%|██████████| 786/786 [00:22<00:00, 34.73it/s]\n",
            "[3 / 35]   Val: Loss = 3.98248, PPX = 53.65: 100%|██████████| 95/95 [00:01<00:00, 78.73it/s]\n",
            "[4 / 35] Train: Loss = 3.90705, PPX = 49.75:   1%|          | 5/786 [00:00<00:33, 23.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 5.21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[4 / 35] Train: Loss = 3.66598, PPX = 39.09: 100%|██████████| 786/786 [00:22<00:00, 35.40it/s]\n",
            "[4 / 35]   Val: Loss = 3.77628, PPX = 43.65: 100%|██████████| 95/95 [00:01<00:00, 78.85it/s]\n",
            "[5 / 35] Train: Loss = 4.21766, PPX = 67.87:   1%|          | 5/786 [00:00<00:42, 18.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 6.92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5 / 35] Train: Loss = 3.37778, PPX = 29.31: 100%|██████████| 786/786 [00:22<00:00, 35.53it/s]\n",
            "[5 / 35]   Val: Loss = 3.59075, PPX = 36.26: 100%|██████████| 95/95 [00:01<00:00, 79.29it/s]\n",
            "[6 / 35] Train: Loss = 3.54573, PPX = 34.66:   1%|          | 5/786 [00:00<00:40, 19.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 8.94\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6 / 35] Train: Loss = 3.13372, PPX = 22.96: 100%|██████████| 786/786 [00:21<00:00, 35.84it/s]\n",
            "[6 / 35]   Val: Loss = 3.43560, PPX = 31.05: 100%|██████████| 95/95 [00:01<00:00, 78.35it/s]\n",
            "[7 / 35] Train: Loss = 2.41349, PPX = 11.17:   1%|          | 6/786 [00:00<00:28, 26.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 11.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7 / 35] Train: Loss = 2.92075, PPX = 18.56: 100%|██████████| 786/786 [00:22<00:00, 35.64it/s]\n",
            "[7 / 35]   Val: Loss = 3.33264, PPX = 28.01: 100%|██████████| 95/95 [00:01<00:00, 77.84it/s]\n",
            "[8 / 35] Train: Loss = 2.38917, PPX = 10.90:   1%|          | 6/786 [00:00<00:29, 26.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 12.08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8 / 35] Train: Loss = 2.74058, PPX = 15.50: 100%|██████████| 786/786 [00:21<00:00, 35.82it/s]\n",
            "[8 / 35]   Val: Loss = 3.24672, PPX = 25.71: 100%|██████████| 95/95 [00:01<00:00, 80.11it/s]\n",
            "[9 / 35] Train: Loss = 2.82093, PPX = 16.79:   1%|          | 5/786 [00:00<00:29, 26.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 13.26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9 / 35] Train: Loss = 2.58002, PPX = 13.20: 100%|██████████| 786/786 [00:22<00:00, 35.63it/s]\n",
            "[9 / 35]   Val: Loss = 3.19319, PPX = 24.37: 100%|██████████| 95/95 [00:01<00:00, 80.28it/s]\n",
            "[10 / 35] Train: Loss = 1.49619, PPX = 4.46:   1%|          | 6/786 [00:00<00:28, 27.19it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 13.86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[10 / 35] Train: Loss = 2.43808, PPX = 11.45: 100%|██████████| 786/786 [00:21<00:00, 35.87it/s]\n",
            "[10 / 35]   Val: Loss = 3.12165, PPX = 22.68: 100%|██████████| 95/95 [00:01<00:00, 77.90it/s]\n",
            "[11 / 35] Train: Loss = 1.51901, PPX = 4.57:   1%|          | 7/786 [00:00<00:24, 31.65it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 14.58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[11 / 35] Train: Loss = 2.31174, PPX = 10.09: 100%|██████████| 786/786 [00:21<00:00, 36.04it/s]\n",
            "[11 / 35]   Val: Loss = 3.08245, PPX = 21.81: 100%|██████████| 95/95 [00:01<00:00, 80.26it/s]\n",
            "[12 / 35] Train: Loss = 2.32432, PPX = 10.22:   1%|          | 5/786 [00:00<00:29, 26.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 14.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[12 / 35] Train: Loss = 2.19724, PPX = 9.00: 100%|██████████| 786/786 [00:22<00:00, 34.69it/s]\n",
            "[12 / 35]   Val: Loss = 3.04814, PPX = 21.08: 100%|██████████| 95/95 [00:01<00:00, 75.41it/s]\n",
            "[13 / 35] Train: Loss = 2.44004, PPX = 11.47:   1%|          | 6/786 [00:00<00:26, 29.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 15.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[13 / 35] Train: Loss = 2.09673, PPX = 8.14: 100%|██████████| 786/786 [00:22<00:00, 34.95it/s]\n",
            "[13 / 35]   Val: Loss = 3.03157, PPX = 20.73: 100%|██████████| 95/95 [00:01<00:00, 78.61it/s]\n",
            "[14 / 35] Train: Loss = 0.56481, PPX = 1.76:   1%|          | 5/786 [00:00<00:40, 19.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 15.66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[14 / 35] Train: Loss = 2.00494, PPX = 7.43: 100%|██████████| 786/786 [00:21<00:00, 35.73it/s]\n",
            "[14 / 35]   Val: Loss = 2.99231, PPX = 19.93: 100%|██████████| 95/95 [00:01<00:00, 82.27it/s]\n",
            "[15 / 35] Train: Loss = 2.84585, PPX = 17.22:   1%|          | 5/786 [00:00<00:31, 24.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 16.24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[15 / 35] Train: Loss = 1.91949, PPX = 6.82: 100%|██████████| 786/786 [00:21<00:00, 35.95it/s]\n",
            "[15 / 35]   Val: Loss = 2.96873, PPX = 19.47: 100%|██████████| 95/95 [00:01<00:00, 77.52it/s]\n",
            "[16 / 35] Train: Loss = 1.84557, PPX = 6.33:   1%|          | 4/786 [00:00<00:41, 18.92it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 16.27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[16 / 35] Train: Loss = 1.84555, PPX = 6.33: 100%|██████████| 786/786 [00:21<00:00, 35.77it/s]\n",
            "[16 / 35]   Val: Loss = 2.96463, PPX = 19.39: 100%|██████████| 95/95 [00:01<00:00, 77.93it/s]\n",
            "[17 / 35] Train: Loss = 1.69975, PPX = 5.47:   1%|          | 6/786 [00:00<00:25, 30.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 16.61\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[17 / 35] Train: Loss = 1.77380, PPX = 5.89: 100%|██████████| 786/786 [00:22<00:00, 35.72it/s]\n",
            "[17 / 35]   Val: Loss = 2.94289, PPX = 18.97: 100%|██████████| 95/95 [00:01<00:00, 79.20it/s]\n",
            "[18 / 35] Train: Loss = 1.89265, PPX = 6.64:   1%|          | 6/786 [00:00<00:28, 27.81it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 16.94\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[18 / 35] Train: Loss = 1.71137, PPX = 5.54: 100%|██████████| 786/786 [00:22<00:00, 35.46it/s]\n",
            "[18 / 35]   Val: Loss = 2.93495, PPX = 18.82: 100%|██████████| 95/95 [00:01<00:00, 79.93it/s]\n",
            "[19 / 35] Train: Loss = 0.22658, PPX = 1.25:   1%|          | 6/786 [00:00<00:40, 19.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[19 / 35] Train: Loss = 1.65205, PPX = 5.22: 100%|██████████| 786/786 [00:22<00:00, 34.56it/s]\n",
            "[19 / 35]   Val: Loss = 2.92817, PPX = 18.69: 100%|██████████| 95/95 [00:01<00:00, 79.08it/s]\n",
            "[20 / 35] Train: Loss = 1.83132, PPX = 6.24:   1%|          | 6/786 [00:00<00:28, 27.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[20 / 35] Train: Loss = 1.59605, PPX = 4.93: 100%|██████████| 786/786 [00:22<00:00, 34.85it/s]\n",
            "[20 / 35]   Val: Loss = 2.93279, PPX = 18.78: 100%|██████████| 95/95 [00:01<00:00, 78.59it/s]\n",
            "[21 / 35] Train: Loss = 0.33112, PPX = 1.39:   1%|          | 5/786 [00:00<00:34, 22.71it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 16.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[21 / 35] Train: Loss = 1.54491, PPX = 4.69: 100%|██████████| 786/786 [00:21<00:00, 36.11it/s]\n",
            "[21 / 35]   Val: Loss = 2.92541, PPX = 18.64: 100%|██████████| 95/95 [00:01<00:00, 78.77it/s]\n",
            "[22 / 35] Train: Loss = 1.48965, PPX = 4.44:   1%|          | 4/786 [00:00<00:34, 22.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[22 / 35] Train: Loss = 1.49624, PPX = 4.46: 100%|██████████| 786/786 [00:22<00:00, 35.13it/s]\n",
            "[22 / 35]   Val: Loss = 2.92588, PPX = 18.65: 100%|██████████| 95/95 [00:01<00:00, 77.22it/s]\n",
            "[23 / 35] Train: Loss = 1.13635, PPX = 3.12:   1%|          | 4/786 [00:00<00:44, 17.70it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[23 / 35] Train: Loss = 1.45118, PPX = 4.27: 100%|██████████| 786/786 [00:22<00:00, 34.30it/s]\n",
            "[23 / 35]   Val: Loss = 2.92855, PPX = 18.70: 100%|██████████| 95/95 [00:01<00:00, 75.77it/s]\n",
            "[24 / 35] Train: Loss = 1.94233, PPX = 6.98:   1%|          | 5/786 [00:00<00:30, 25.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[24 / 35] Train: Loss = 1.40751, PPX = 4.09: 100%|██████████| 786/786 [00:22<00:00, 34.76it/s]\n",
            "[24 / 35]   Val: Loss = 2.91964, PPX = 18.53: 100%|██████████| 95/95 [00:01<00:00, 77.46it/s]\n",
            "[25 / 35] Train: Loss = 1.37768, PPX = 3.97:   1%|          | 4/786 [00:00<00:41, 18.93it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[25 / 35] Train: Loss = 1.36973, PPX = 3.93: 100%|██████████| 786/786 [00:22<00:00, 34.56it/s]\n",
            "[25 / 35]   Val: Loss = 2.92584, PPX = 18.65: 100%|██████████| 95/95 [00:01<00:00, 74.44it/s]\n",
            "[26 / 35] Train: Loss = 2.89522, PPX = 18.09:   1%|          | 5/786 [00:00<00:32, 23.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.74\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[26 / 35] Train: Loss = 1.33277, PPX = 3.79: 100%|██████████| 786/786 [00:23<00:00, 33.17it/s]\n",
            "[26 / 35]   Val: Loss = 2.93439, PPX = 18.81: 100%|██████████| 95/95 [00:01<00:00, 75.15it/s]\n",
            "[27 / 35] Train: Loss = 1.86213, PPX = 6.44:   1%|          | 4/786 [00:00<00:43, 18.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 18.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[27 / 35] Train: Loss = 1.29702, PPX = 3.66: 100%|██████████| 786/786 [00:23<00:00, 33.04it/s]\n",
            "[27 / 35]   Val: Loss = 2.94069, PPX = 18.93: 100%|██████████| 95/95 [00:01<00:00, 74.98it/s]\n",
            "[28 / 35] Train: Loss = 0.98051, PPX = 2.67:   1%|          | 4/786 [00:00<00:41, 18.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[28 / 35] Train: Loss = 1.26560, PPX = 3.55: 100%|██████████| 786/786 [00:23<00:00, 34.02it/s]\n",
            "[28 / 35]   Val: Loss = 2.96412, PPX = 19.38: 100%|██████████| 95/95 [00:01<00:00, 78.26it/s]\n",
            "[29 / 35] Train: Loss = 1.46460, PPX = 4.33:   1%|          | 5/786 [00:00<00:33, 23.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.74\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[29 / 35] Train: Loss = 1.23461, PPX = 3.44: 100%|██████████| 786/786 [00:22<00:00, 35.06it/s]\n",
            "[29 / 35]   Val: Loss = 2.96534, PPX = 19.40: 100%|██████████| 95/95 [00:01<00:00, 77.50it/s]\n",
            "[30 / 35] Train: Loss = 0.94557, PPX = 2.57:   1%|          | 5/786 [00:00<00:34, 22.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[30 / 35] Train: Loss = 1.20557, PPX = 3.34: 100%|██████████| 786/786 [00:22<00:00, 34.97it/s]\n",
            "[30 / 35]   Val: Loss = 2.96851, PPX = 19.46: 100%|██████████| 95/95 [00:01<00:00, 77.98it/s]\n",
            "[31 / 35] Train: Loss = 0.17147, PPX = 1.19:   1%|          | 5/786 [00:00<00:35, 21.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 18.31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[31 / 35] Train: Loss = 1.17584, PPX = 3.24: 100%|██████████| 786/786 [00:22<00:00, 35.16it/s]\n",
            "[31 / 35]   Val: Loss = 2.98702, PPX = 19.83: 100%|██████████| 95/95 [00:01<00:00, 79.10it/s]\n",
            "[32 / 35] Train: Loss = 0.85934, PPX = 2.36:   1%|          | 6/786 [00:00<00:28, 27.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.94\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[32 / 35] Train: Loss = 1.15108, PPX = 3.16: 100%|██████████| 786/786 [00:22<00:00, 35.12it/s]\n",
            "[32 / 35]   Val: Loss = 2.99040, PPX = 19.89: 100%|██████████| 95/95 [00:01<00:00, 77.34it/s]\n",
            "[33 / 35] Train: Loss = 1.63594, PPX = 5.13:   1%|          | 4/786 [00:00<00:42, 18.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.97\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[33 / 35] Train: Loss = 1.12558, PPX = 3.08: 100%|██████████| 786/786 [00:21<00:00, 35.76it/s]\n",
            "[33 / 35]   Val: Loss = 2.99083, PPX = 19.90: 100%|██████████| 95/95 [00:01<00:00, 80.52it/s]\n",
            "[34 / 35] Train: Loss = 0.76019, PPX = 2.14:   1%|          | 6/786 [00:00<00:26, 29.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 18.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[34 / 35] Train: Loss = 1.10189, PPX = 3.01: 100%|██████████| 786/786 [00:21<00:00, 35.81it/s]\n",
            "[34 / 35]   Val: Loss = 3.01267, PPX = 20.34: 100%|██████████| 95/95 [00:01<00:00, 77.82it/s]\n",
            "[35 / 35] Train: Loss = 0.81718, PPX = 2.26:   1%|          | 4/786 [00:00<00:40, 19.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 18.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[35 / 35] Train: Loss = 1.08140, PPX = 2.95: 100%|██████████| 786/786 [00:21<00:00, 35.83it/s]\n",
            "[35 / 35]   Val: Loss = 3.03691, PPX = 20.84: 100%|██████████| 95/95 [00:01<00:00, 79.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Val BLEU = 17.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lysZXVNf-iKs"
      },
      "source": [
        "## Про метрики"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcBSJRbl-uXm"
      },
      "source": [
        "**PPX** (перплексия) - в литературе, это измерение того, насколько хорошо языковая модель предсказывает выборку. По факту:\n",
        "$$2^{H(p)} = 2^{\\sum_x p(x)\\log_2p(x)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1c99dJY-zjA"
      },
      "source": [
        "**BLEU**  - рассматривает совпадение предсказанных и фактических целевых последовательностей с \n",
        "точки зрения n-gramm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWEx0FlKzGHY"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypWsq1tmzfDG"
      },
      "source": [
        "def gec(model, source_text, source_field, target_field):\n",
        "    bos_index = target_field.vocab.stoi['<s>']\n",
        "    eos_index = target_field.vocab.stoi['</s>']\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        result = []\n",
        "        source = source_field.preprocess(source_text)\n",
        "        inputs = source_field.process([source])\n",
        "        len_inputs = inputs[1].to(DEVICE)\n",
        "        input = inputs[0].to(DEVICE)\n",
        "        \n",
        "        encoder_output, encoder_hidden = model.encoder(input, len_inputs)\n",
        "        encoder_mask = torch.zeros_like(input).byte()\n",
        "        \n",
        "        output = encoder_output\n",
        "        hidden = encoder_hidden\n",
        "        step = LongTensor([[bos_index]])\n",
        "        \n",
        "        for _ in range(50):\n",
        "            step, hidden, _ = model.decoder(step, encoder_output, encoder_mask, encoder_hidden, output, hidden)\n",
        "            step = step.argmax(-1)\n",
        "          \n",
        "            if step.squeeze().item() == eos_index:\n",
        "                break\n",
        "            \n",
        "            result.append(step.item())   \n",
        "        result = [target_field.vocab.itos[ind] for ind in result]\n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkADB9Ke0a8J",
        "outputId": "c786deda-9cdb-4b91-cb2f-cc9da4644843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "text = 'The rich people will buy a car but the poor people always need to use a bus or taxi.'\n",
        "result = gec(model, text, source_field, target_field)\n",
        "print(f'Исходная запись: {text}')\n",
        "print(f'Предсказание: {\" \".join(result)}')\n",
        "print(f'Должно быть: Rich people will buy a car , but poor people always need to use a bus or taxi .')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Исходная запись: The rich people will buy a car but the poor people always need to use a bus or taxi.\n",
            "Предсказание: people will expensive people every colour because the people will not even change .\n",
            "Должно быть: Rich people will buy a car , but poor people always need to use a bus or taxi .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm7MLmN7ETYs"
      },
      "source": [
        "Немного переобучил модель, но все равно смешно:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83RkmQRF-9_C",
        "outputId": "98347de3-4e0e-464f-fd51-5f2f26d05bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "text = 'The rich people will buy a car but the poor people always need to use a bus or taxi.'\n",
        "result = gec(model, text, source_field, target_field)\n",
        "print(f'Исходная запись: {text}')\n",
        "print(f'Предсказание: {\" \".join(result)}')\n",
        "print(f'Должно быть: Rich people will buy a car , but poor people always need to use a bus or taxi .')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Исходная запись: The rich people will buy a car but the poor people always need to use a bus or taxi.\n",
            "Предсказание: the people should buy people expensive people , the people will buy people expensive people to buy a car , people will change the people need a car .\n",
            "Должно быть: Rich people will buy a car , but poor people always need to use a bus or taxi .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP2NpUdC2hM2"
      },
      "source": [
        "![эх](https://i.ytimg.com/vi/sruJfntXMYE/hqdefault.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmtX6KPH_ikZ"
      },
      "source": [
        "## Почему так плохо?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPvcQKwJ_k-r"
      },
      "source": [
        "Варианты:\n",
        "1. Я использовал teacher forcing (в качестве выхода на предыдущем шаге декодер принимал всегда правильный токен). Модель короче на хороших входах, а использоваться будет скорее всего на плохом\n",
        "2. Я реализовал жадный перевод. на каждом шаге предсказывал наиболее вероятный токен, можно докинуть beam search\n",
        "3. Не смог подкрутить двунаправленность \n",
        "4. Ну камон, какая seq2seq с rnn ? Надо чет мощнее.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s582M8mOqVAL"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auj4h1GWBwks"
      },
      "source": [
        "![transformer](https://hsto.org/webt/59/f0/44/59f04410c0e56192990801.png)  \n",
        "*From Attention is all you need*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPC-pIlUqxeX"
      },
      "source": [
        "## Данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfSFVcxq4B8I",
        "outputId": "55973eb5-8843-421b-b98d-bcacea5caf30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "train_path = 'seq2seq/data/train.txt'\n",
        "val_path = 'seq2seq/data/dev.txt'\n",
        "prepare = PrepareData(train_path, val_path, batch_size=32,\n",
        "                      batch_first=True, include_lingths=False,\n",
        "                      init_token=True)\n",
        "train_iter, test_iter, source_field, target_field = prepare.start()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34304/34304 [00:07<00:00, 4648.15it/s]\n",
            "100%|██████████| 4384/4384 [00:00<00:00, 4403.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size = 25146\n",
            "Test size = 3015\n",
            "Example data =  {'source': ['my', 'town', 'is', 'a', 'medium', 'size', 'city', 'with', 'eighty', 'thousand', 'inhabitants', '.'], 'target': ['my', 'town', 'is', 'a', 'medium', '-', 'sized', 'city', 'with', 'eighty', 'thousand', 'inhabitants', '.']}\n",
            "Source vocab size = 7568\n",
            "Target vocab size = 7509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2HMt2LKqwq2"
      },
      "source": [
        "## Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxfMKUocC3PM"
      },
      "source": [
        "Весь Transformer опирается на идею self-attention. Выглядит это так:\n",
        "\n",
        "![](http://jalammar.github.io/images/t/transformer_self-attention_visualization.png)  \n",
        "*From [Tensor2Tensor Tutorial](https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb)*\n",
        "\n",
        "Эмбеддинг слова *it* строится как комбинация всех эмбеддингов предложения.\n",
        "\n",
        "В статье придумали делать такой аттеншен:\n",
        "\n",
        "$$\\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
        "\n",
        "Это примерно как dot-attention: запрос (**Q**uery) умножается на ключи (**K**ey) скалярно, затем берется софтмакс - получаются оценки того, насколько интересны разные таймстемпы из значений (**V**alue). \n",
        "\n",
        "Например, $\\mathrm{emb}(\\text{it}) = \\mathrm{Attention}(\\text{it}, \\ldots\\text{because it was too tired}, \\ldots\\text{because it was too tired})$.\n",
        "\n",
        "Только теперь ещё с параметром $\\frac{1}{\\sqrt{d_k}}$, где $d_k$ - это размерность ключа. Утверждается, это работает лучше при больших размерностях ключа $d_k$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmseNsEtDDgF"
      },
      "source": [
        "![](https://hsto.org/webt/59/f0/44/59f0440f1109b864893781.png)\n",
        "\n",
        "Важная идея, почему attention (и, главное, self-attention) заработал - использование нескольких голов (multi-head).\n",
        "\n",
        "Вообще, когда мы делаем attention - мы определяем похожесть ключа и запроса. Многоголовость помогает (должна) определять эту похожесть по разным критериям - синтаксически, семантически и т.д.\n",
        "\n",
        "Применяется это таким образом:\n",
        "\n",
        "$$\\mathrm{MultiHead}(Q, K, V) = \\mathrm{Concat}(\\mathrm{head_1}, ...,\n",
        "\\mathrm{head_h})W^O    \\\\\n",
        "    \\mathrm{head_i} = \\mathrm{Attention}(QW^Q_i, KW^K_i, VW^V_i)$$\n",
        "    \n",
        "где $W^Q_i \\in \\mathbb{R}^{d_{model} \\times d_k}, W_i^K \\in \\mathbb{R}^{d_{model} \\times d_k}, W^V_i \\in \\mathbb{R}^{d_{model} \\times d_v}, W^O \\in \\mathbb{R}^{hd_v \\times d_{model}}$.\n",
        "\n",
        "В оригинальной статье использовали $h=8$, $d_k=d_v=d_{\\text{model}}/h=64$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtuQSOCiqHjn"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, hid_dim,  n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        #q = [batch size, query len, hid dim]\n",
        "        #k = [batch size, key len, hid dim]\n",
        "        #v = [batch size, value len, hid dim]\n",
        "        batch_size = q.shape[0]\n",
        "\n",
        "        q = self.fc_q(q)\n",
        "        k = self.fc_k(k)\n",
        "        v = self.fc_v(v)\n",
        "\n",
        "        q = q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        k = k.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        v = v.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        #q = [batch size, n heads, query len, head dim]\n",
        "        #k = [batch size, n heads, key len, head dim]\n",
        "        #v = [batch size, n heads, value len, head dim]\n",
        "\n",
        "        dot_product = torch.matmul(q, k.permute(0, 1, 3, 2)) / self.scale\n",
        "        #dot_product = [batch size, n heads, query len, key len]\n",
        "\n",
        "        attention = torch.softmax(dot_product, dim=-1)\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), v)\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        x = self.fc_o(x)\n",
        "        #x = [batch size, query len, hid dim]\n",
        "        return x, attention"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJANeFkvCAeW"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3GQbdZ5q3AZ"
      },
      "source": [
        "class FeedForwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        x = self.fc_1(x)\n",
        "        x = self.dropout(self.relu(x))\n",
        "\n",
        "        return self.fc_2(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYd9ZpVpq4x_"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttention(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward = FeedForwardLayer(hid_dim, pf_dim, dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, src len]\n",
        "\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        src = self.layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        _src = self.feedforward(src)\n",
        "        src = self.layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        return src"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IXxRJ7yq6oY"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads,\n",
        "                 pf_dim, dropout, device, max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP0rewRjCDFq"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY-MeaSdq9qP"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttention(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttention(hid_dim, n_heads, dropout, device)\n",
        "        self.feedforward = FeedForwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, trg len]\n",
        "        #src_mask = [batch size, src len]\n",
        "        \n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        trg = self.layer_norm(trg + self.dropout(_trg))\n",
        "                        \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        _trg = self.feedforward(trg)\n",
        "        \n",
        "        trg = self.layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrB_aYljq_Sm"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 100):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, trg len]\n",
        "        #src_mask = [batch size, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ooCdaA7CFSU"
      },
      "source": [
        "## Полная модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dg6aw-FrBB_"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool() # tril - возвращет треугольную часть матрицы\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2ERjn_F5KAr"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLVRijkRCITW"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Ee8coNrFhK",
        "outputId": "6d52f94e-2e3a-4a1a-9749-5723654e5a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from seq2seq.utils.utilsTransformer import *\n",
        "\n",
        "input_dim = len(source_field.vocab)\n",
        "output_dim = len(target_field.vocab)\n",
        "hiiden_dim = 256\n",
        "encoder_layers = 3\n",
        "decoder_layers = 3\n",
        "encoder_heads = 8\n",
        "decoder_heads = 8\n",
        "encoder_pf_dim = 512\n",
        "decoder_pf_dim = 512\n",
        "encoder_dropout = 0.1\n",
        "decoder_dropout = 0.1\n",
        "\n",
        "enc = Encoder(input_dim, hiiden_dim, encoder_layers,\n",
        "              encoder_heads, encoder_pf_dim, encoder_dropout,\n",
        "              DEVICE)\n",
        "\n",
        "dec = Decoder(output_dim, hiiden_dim, decoder_layers,\n",
        "              decoder_heads, decoder_pf_dim, decoder_dropout,\n",
        "              DEVICE)\n",
        "\n",
        "SRC_PAD_IDX = source_field.vocab.stoi[source_field.pad_token]\n",
        "TRG_PAD_IDX = target_field.vocab.stoi[target_field.pad_token]\n",
        "\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, DEVICE).to(DEVICE)\n",
        "\n",
        "model.apply(initialize_weights);\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "out = fit(model, criterion, optimizer, train_iter, epochs_count=5, val_iter=test_iter)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 5] Train: Loss = 3.03333, PPX = 20.77: 100%|██████████| 786/786 [00:31<00:00, 24.97it/s]\n",
            "[1 / 5]   Val: Loss = 0.81273, PPX = 2.25: 100%|██████████| 95/95 [00:01<00:00, 93.40it/s]\n",
            "[2 / 5] Train: Loss = 0.60465, PPX = 1.83: 100%|██████████| 786/786 [00:30<00:00, 26.09it/s]\n",
            "[2 / 5]   Val: Loss = 0.27219, PPX = 1.31: 100%|██████████| 95/95 [00:01<00:00, 91.68it/s]\n",
            "[3 / 5] Train: Loss = 0.27155, PPX = 1.31: 100%|██████████| 786/786 [00:29<00:00, 26.26it/s]\n",
            "[3 / 5]   Val: Loss = 0.12393, PPX = 1.13: 100%|██████████| 95/95 [00:00<00:00, 97.10it/s]\n",
            "[4 / 5] Train: Loss = 0.13670, PPX = 1.15: 100%|██████████| 786/786 [00:30<00:00, 26.05it/s]\n",
            "[4 / 5]   Val: Loss = 0.05904, PPX = 1.06: 100%|██████████| 95/95 [00:00<00:00, 95.32it/s]\n",
            "[5 / 5] Train: Loss = 0.07777, PPX = 1.08: 100%|██████████| 786/786 [00:29<00:00, 26.45it/s]\n",
            "[5 / 5]   Val: Loss = 0.03317, PPX = 1.03: 100%|██████████| 95/95 [00:01<00:00, 91.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8KjVUiJLeNs",
        "outputId": "6ed05b8e-45dc-41a7-ae2c-bdcfcc26574c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(out)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 7.4964, -0.8494, -0.7168,  ..., -0.0224,  0.3387, -1.6041],\n",
            "        [ 3.1933, -0.6607, -0.2058,  ..., -1.6023,  0.3649, -1.1363],\n",
            "        [ 2.2783, -1.2862, -1.2607,  ..., -4.7473, -4.2382, -2.4925],\n",
            "        ...,\n",
            "        [ 7.1153, -0.5686,  0.1196,  ..., -0.4088, -2.7209, -0.6260],\n",
            "        [ 3.0427, -1.6337, -1.7286,  ...,  0.9973, -1.2783,  0.1864],\n",
            "        [ 4.6235, -2.2453, -2.8410,  ...,  0.8970,  1.1595,  0.3482]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGVwI7AQGHek"
      },
      "source": [
        "def gec_transformer(model, sentence, source_field, target_field):\n",
        "    bos_index = target_field.vocab.stoi['<s>']\n",
        "    eos_index = target_field.vocab.stoi['</s>']\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        result, attention = [], []\n",
        "        source = source_field.preprocess(sentence)\n",
        "        inputs = source_field.process([source]).to(DEVICE)\n",
        "\n",
        "        src_mask = model.make_src_mask(inputs)\n",
        "        enc_src = model.encoder(inputs, src_mask)\n",
        "\n",
        "        step = [bos_index]\n",
        "\n",
        "        for _ in range(50):\n",
        "            step = LongTensor(step).unsqueeze(0).to(DEVICE)\n",
        "            trg_mask = model.make_trg_mask(step)\n",
        "            step, _ = model.decoder(step, enc_src, trg_mask, src_mask)\n",
        "            step = step.argmax(2)[:,-1].item()\n",
        "            result.append(step)\n",
        "\n",
        "            if step == eos_index:\n",
        "                break\n",
        "\n",
        "        \n",
        "        result = [target_field.vocab.itos[ind] for ind in result]\n",
        "        return result"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_0PEtCurIal",
        "outputId": "edafd2b4-1777-4a56-b711-d9ca6a1ad514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "text = 'The rich people will buy a car but the poor people always need to use a bus or taxi.'\n",
        "result = gec_transformer(model, text, source_field, target_field)\n",
        "print(f'Исходная запись: {text}')\n",
        "print(f'Предсказание: {\" \".join(result)}')\n",
        "print(f'Должно быть: Rich people will buy a car , but poor people always need to use a bus or taxi .')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-851492b386ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'The rich people will buy a car but the poor people always need to use a bus or taxi.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgec_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_field\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Исходная запись: {text}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Предсказание: {\" \".join(result)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Должно быть: Rich people will buy a car , but poor people always need to use a bus or taxi .'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-d8f4efcf95bf>\u001b[0m in \u001b[0;36mgec_transformer\u001b[0;34m(model, sentence, source_field, target_field)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtrg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_trg_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK1Sj2vhGUaS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}