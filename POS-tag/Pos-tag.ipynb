{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0LX-dZCj9FY",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12ceSx8nxm7vRb4vacsjBHGdz6nXh3tCc?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw5CzdRDMugA",
        "colab_type": "text"
      },
      "source": [
        "# Техническая часть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4lNO-l69D7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9c2b96c2-90ef-43aa-fdd0-0c1cdf6b4987"
      },
      "source": [
        "!pip install navec\n",
        "!pip install razdel"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: navec in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from navec) (1.18.5)\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REIjImPYIYbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "train_text_dwld = drive.CreateFile({'id':'11pMg8DdZ56edNBs647k0qDjOPmeFNLPM'})\n",
        "train_text_dwld.GetContentFile('train.csv')\n",
        "\n",
        "train_text_dwld = drive.CreateFile({'id':'1o0ruW9qzbHqm1buCQQcknyIghHeRBXym'})\n",
        "train_text_dwld.GetContentFile('navec_hudlit_v1_12B_500K_300d_100q.tar')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFebxMnc227Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import io\n",
        "import collections\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from navec import Navec\n",
        "from razdel import tokenize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from torchtext.data import Field, Example, Dataset, BucketIterator\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWW6snp7wjwn",
        "colab_type": "text"
      },
      "source": [
        "# Данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lPsakRaRppM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentences(filename, is_train):\n",
        "    sentences = []\n",
        "    with io.open(filename, \"r\", encoding='utf-8') as r:\n",
        "        # Пропускаем заголовок\n",
        "        next(r)\n",
        "        sentence = [] # будем заполнять список предложений\n",
        "        for line in r:\n",
        "            # предложения отделены по '\\n'\n",
        "            if len(line.strip()) == 0:\n",
        "                if len(sentence) == 0:\n",
        "                    continue\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "                continue\n",
        "            if is_train:\n",
        "                # Формат: индекс\\tномер_в_предложении\\tсловоформа\\tPOS#Грамемы\n",
        "                word = line.strip().split(\"\\t\")[2]\n",
        "                pos = line.strip().split(\"\\t\")[3].split(\"#\")[0]\n",
        "                # gram = line.strip().split(\"\\t\")[3].split(\"#\")[1]\n",
        "                sentence.append((word, pos))\n",
        "            else:\n",
        "                word = line.strip().split(\"\\t\")[2]\n",
        "                sentence.append(word)\n",
        "        if len(sentence) != 0:\n",
        "            sentences.append(sentence)\n",
        "    return sentences\n",
        "\n",
        "train = get_sentences('train.csv', True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6r4jxBpXfd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "418026ef-f8a2-442b-ff4e-fab87a7eff11"
      },
      "source": [
        "for word, tag in train[0][:10]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "А              \tCONJ\n",
            "ведь           \tPART\n",
            "для            \tADP\n",
            "конкретных     \tADJ\n",
            "изделий        \tNOUN\n",
            "зачастую       \tADV\n",
            "нужен          \tADJ\n",
            "монокристалл   \tNOUN\n",
            "не             \tPART\n",
            "только         \tPART\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1QqSQdYcCd5",
        "colab_type": "text"
      },
      "source": [
        "## Подготовка к torchtext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDDdgebKaE5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def razdel_tokenizer(text):\n",
        "    tokens = list(tokenize(text))\n",
        "    tokens = [_.text for _ in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ljpfkGIXsYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(sentences):\n",
        "    examples = []\n",
        "    fields = {'sentence_labels': ('labels', label_field),\n",
        "              'sentence_tokens': ('text', text_field)}\n",
        "    \n",
        "    for sentence in sentences: \n",
        "        tokens = [t[0] for t in sentence]\n",
        "        labels = [t[1] for t in sentence]\n",
        "        \n",
        "        e = Example.fromdict({\"sentence_labels\": labels, \"sentence_tokens\": tokens},\n",
        "                             fields=fields)\n",
        "        examples.append(e)\n",
        "    \n",
        "    return Dataset(examples, fields=[('labels', label_field), ('text', text_field)])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn7ojTJLaMTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "caa8bd50-cd3a-425b-8f52-8e816780111d"
      },
      "source": [
        "text_field = Field(sequential=True, tokenize=razdel_tokenizer, include_lengths=True)\n",
        "label_field = Field(sequential=True, is_target=True)\n",
        "\n",
        "train_data, valid_data = train_test_split(train, test_size=0.1)\n",
        "\n",
        "train_data = read_data(train_data)\n",
        "val_data = read_data(valid_data)\n",
        "\n",
        "print(train_data[0].text)\n",
        "print(train_data[0].labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Вскоре', 'мы', 'познакомились', ',', 'и', 'я', 'убедился', 'в', 'том', ',', 'что', 'кроме', 'привлекательной', 'внешности', 'она', 'обладает', 'редкой', 'способностью', 'очень', 'здраво', 'рассуждать', 'о', 'самых', 'разных', 'вещах', 'и', 'событиях', '.']\n",
            "['ADV', 'PRON', 'VERB', 'PUNCT', 'CONJ', 'PRON', 'VERB', 'ADP', 'PRON', 'PUNCT', 'SCONJ', 'ADP', 'ADJ', 'NOUN', 'PRON', 'VERB', 'ADJ', 'NOUN', 'ADV', 'ADV', 'VERB', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'CONJ', 'NOUN', 'PUNCT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFgogc0wYBkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_field.build_vocab(train_data)\n",
        "label_field.build_vocab(train_data)\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, val_data),\n",
        "    shuffle=True,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    batch_size = 64,\n",
        "    device = device)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwVdtW8-aQZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04cb871d-455d-4f12-b8a0-7f77033a3dc8"
      },
      "source": [
        "path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
        "navec = Navec.load(path)\n",
        "\n",
        "navec['привет'].shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djehjQ_9cG8H",
        "colab_type": "text"
      },
      "source": [
        "## Строим embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajhy482eZOTd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b08feaf8-a85a-4848-8159-5e471a724518"
      },
      "source": [
        "known_count = 0\n",
        "unk_word = []\n",
        "embeddings = np.zeros((len(text_field.vocab), 300))\n",
        "for idx, word in tqdm(enumerate(text_field.vocab.itos), total=len(text_field.vocab)):\n",
        "    word = word.lower()\n",
        "    if word in navec:\n",
        "        embeddings[idx] = navec[word]\n",
        "        known_count += 1\n",
        "    else:\n",
        "        unk_word.append(word)\n",
        "print()\n",
        "print(f'navec знает {known_count} слов')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 101296/101296 [00:01<00:00, 85759.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "navec знает 89134 слов\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpAw2_5KaaJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "9c0336a3-62e5-4863-f99a-c53548a84d7c"
      },
      "source": [
        "unk_word[0:25]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',',\n",
              " '.',\n",
              " '\"',\n",
              " '-',\n",
              " ':',\n",
              " ')',\n",
              " '(',\n",
              " '?',\n",
              " '!',\n",
              " '…',\n",
              " '%',\n",
              " ';',\n",
              " '10',\n",
              " 'а_также',\n",
              " 'потому_что',\n",
              " 'то_есть',\n",
              " '1',\n",
              " '20',\n",
              " '15',\n",
              " '2',\n",
              " '5',\n",
              " 'с_помощью',\n",
              " 'во_время',\n",
              " '3',\n",
              " '30']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw8fLI4zkQvD",
        "colab_type": "text"
      },
      "source": [
        "Не понятно, что делать с такими словами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tZpZOKDZ250",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LGMShlFcWKu",
        "colab_type": "text"
      },
      "source": [
        "В качестве модели, буду использовать обычную bi-GRU с pack_padded_sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPnzsaPjkVhX",
        "colab_type": "text"
      },
      "source": [
        "Будем дообучать вектора, добавим `freeze=False` в `nn.Embedding.from_pretrained()`  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQSH4x-yfdCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUTagger(nn.Module):\n",
        "    def __init__(self, embeddings, embeddings_dim, tagset_size, gru_hidden_dim=64, gru_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding.from_pretrained(torch.FloatTensor(embeddings), freeze=False)\n",
        "        self.embed_dim = embeddings_dim\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.gru = nn.GRU(self.embed_dim, gru_hidden_dim,\n",
        "                             num_layers=gru_layers_count,\n",
        "                             bidirectional=True)\n",
        "        self.output_layer = nn.Linear(gru_hidden_dim * 2,\n",
        "                                      tagset_size)\n",
        "\n",
        "    def forward(self, text, len_text):\n",
        "        out = self.embed(text)\n",
        "        out = self.dropout(out)\n",
        "        out = pack_padded_sequence(out, len_text)\n",
        "        out, _ = self.gru(out)\n",
        "        out, _ = pad_packed_sequence(out)\n",
        "        out = self.output_layer(out)\n",
        "        return out"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDr_07PjajcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_predictions_for_masked_items(predicted_labels, correct_labels): \n",
        "    predicted_labels_without_mask = []\n",
        "    correct_labels_without_mask = []\n",
        "    for p, c in zip(predicted_labels, correct_labels):\n",
        "        if c > 1:\n",
        "            predicted_labels_without_mask.append(p)\n",
        "            correct_labels_without_mask.append(c)\n",
        "            \n",
        "    return predicted_labels_without_mask, correct_labels_without_mask\n",
        "\n",
        "def do_epoch(model, criterion, data, n_classes, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    epoch_f1 = 0    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=len(data)) as progress_bar:\n",
        "            for batch in data:\n",
        "                text_len, cur_batch_size = batch.text[0].shape\n",
        "                predict = model(batch.text[0].to(device), batch.text[1].to(device)).view(cur_batch_size*text_len, n_classes)\n",
        "                label = batch.labels.view(cur_batch_size*text_len)\n",
        "\n",
        "                loss = criterion(predict, label)\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                _, pred = torch.max(predict, 1)\n",
        "\n",
        "                predict_label = list(pred.cpu().numpy())\n",
        "                correct_label = list(label.cpu().numpy())\n",
        "\n",
        "                predict_label, correct_label = remove_predictions_for_masked_items(predict_label, \n",
        "                                                                                   correct_label)\n",
        "                f1_s = f1_score(predict_label, correct_label, average=\"micro\")\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                epoch_f1 += f1_s\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, f1 = {:.2%}'.format(\n",
        "                    name, loss.item(), f1_s)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, f1 = {:.2%}'.format(\n",
        "                name, epoch_loss / len(data), epoch_f1 / len(data))\n",
        "            )\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, n_classes, epochs_count=1, val_data=None):\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, train_data, n_classes, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if val_data:\n",
        "            val_loss = do_epoch(model, criterion, val_data, n_classes, None, name_prefix + '  Val:')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywJ3yYHrjj7e",
        "colab_type": "text"
      },
      "source": [
        "Будем игнорировать pad, чтобы не обмануть себя и не предсказывать только pad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFtiV9mxbGUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "cddf8748-101a-4664-bfc1-639cdc1e67b3"
      },
      "source": [
        "n_classes = len(label_field.vocab)\n",
        "\n",
        "model = GRUTagger(\n",
        "    embeddings=embeddings,\n",
        "    embeddings_dim=300,\n",
        "    tagset_size=n_classes,\n",
        "    gru_hidden_dim=256,\n",
        "    ).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=label_field.vocab.stoi[label_field.pad_token]).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=train_iterator, n_classes=n_classes, \n",
        "    epochs_count=9, val_data=valid_iterator)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 9] Train: Loss = 0.87004, f1 = 85.84%: 100%|██████████| 678/678 [00:25<00:00, 26.22it/s]\n",
            "[1 / 9]   Val: Loss = 0.42411, f1 = 92.71%: 100%|██████████| 76/76 [00:00<00:00, 88.55it/s]\n",
            "[2 / 9] Train: Loss = 0.22525, f1 = 96.26%: 100%|██████████| 678/678 [00:25<00:00, 26.16it/s]\n",
            "[2 / 9]   Val: Loss = 0.40260, f1 = 93.65%: 100%|██████████| 76/76 [00:00<00:00, 92.34it/s]\n",
            "[3 / 9] Train: Loss = 0.11970, f1 = 98.03%: 100%|██████████| 678/678 [00:26<00:00, 25.91it/s]\n",
            "[3 / 9]   Val: Loss = 0.42744, f1 = 93.80%: 100%|██████████| 76/76 [00:00<00:00, 90.36it/s]\n",
            "[4 / 9] Train: Loss = 0.07792, f1 = 98.71%: 100%|██████████| 678/678 [00:26<00:00, 25.96it/s]\n",
            "[4 / 9]   Val: Loss = 0.41636, f1 = 94.49%: 100%|██████████| 76/76 [00:00<00:00, 93.45it/s]\n",
            "[5 / 9] Train: Loss = 0.05467, f1 = 99.11%: 100%|██████████| 678/678 [00:26<00:00, 25.91it/s]\n",
            "[5 / 9]   Val: Loss = 0.51616, f1 = 93.67%: 100%|██████████| 76/76 [00:00<00:00, 91.98it/s]\n",
            "[6 / 9] Train: Loss = 0.03948, f1 = 99.36%: 100%|██████████| 678/678 [00:26<00:00, 26.03it/s]\n",
            "[6 / 9]   Val: Loss = 0.53048, f1 = 93.83%: 100%|██████████| 76/76 [00:00<00:00, 90.95it/s]\n",
            "[7 / 9] Train: Loss = 0.02943, f1 = 99.52%: 100%|██████████| 678/678 [00:25<00:00, 26.09it/s]\n",
            "[7 / 9]   Val: Loss = 0.52136, f1 = 94.18%: 100%|██████████| 76/76 [00:00<00:00, 93.32it/s]\n",
            "[8 / 9] Train: Loss = 0.02174, f1 = 99.65%: 100%|██████████| 678/678 [00:26<00:00, 25.94it/s]\n",
            "[8 / 9]   Val: Loss = 0.51819, f1 = 94.29%: 100%|██████████| 76/76 [00:00<00:00, 92.73it/s]\n",
            "[9 / 9] Train: Loss = 0.01689, f1 = 99.72%: 100%|██████████| 678/678 [00:26<00:00, 26.00it/s]\n",
            "[9 / 9]   Val: Loss = 0.57557, f1 = 93.82%: 100%|██████████| 76/76 [00:00<00:00, 91.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4bwhiK_U3U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}