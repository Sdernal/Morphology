{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В соревновании на каггл эта модель получила score 0.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8sVtGHmA9aBM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILENAME = \"data/train.csv\"\n",
    "TEST_FILENAME = \"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "WordForm = namedtuple(\"WordForm\", \"word pos gram\")\n",
    "\n",
    "def get_sentences(filename, is_train):\n",
    "    sentences = []\n",
    "    with open(filename, \"r\", encoding='utf-8') as r:\n",
    "        next(r)\n",
    "        sentence = []\n",
    "        for line in r:\n",
    "            if len(line.strip()) == 0:\n",
    "                if len(sentence) == 0:\n",
    "                    continue\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "            if is_train:\n",
    "                word = line.strip().split(\"\\t\")[2]\n",
    "                pos = line.strip().split(\"\\t\")[3].split(\"#\")[0]\n",
    "                gram = line.strip().split(\"\\t\")[3].split(\"#\")[1]\n",
    "                sentence.append(WordForm(word, pos, gram))\n",
    "            else:\n",
    "                word = line.strip().split(\"\\t\")[2]\n",
    "                sentence.append(word)\n",
    "        if len(sentence) != 0:\n",
    "            sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_sentences(TRAIN_FILENAME, True)\n",
    "test = get_sentences(TEST_FILENAME, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12380\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "TiA2dGmgF1rW",
    "outputId": "fb751826-6d53-45df-d7ce-3a472ff2b6fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d93g_swyJA_V"
   },
   "source": [
    "Пример размеченного предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "QstS4NO0L97c",
    "outputId": "ad69f7f3-d8ee-41d1-be89-e35213d74abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А              \t_\n",
      "ведь           \t_\n",
      "для            \t_\n",
      "конкретных     \tCase=Gen|Degree=Pos|Number=Plur\n",
      "изделий        \tAnimacy=Inan|Case=Gen|Gender=Neut|Number=Plur\n",
      "зачастую       \tDegree=Pos\n",
      "нужен          \tDegree=Pos|Gender=Masc|Number=Sing|Variant=Brev\n",
      "монокристалл   \tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "не             \t_\n",
      "только         \t_\n",
      "крупный        \tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
      ",              \t_\n",
      "но             \t_\n",
      "и              \t_\n",
      "заданной       \tAspect=Perf|Case=Gen|Gender=Fem|Number=Sing|Tense=Past|VerbForm=Part|Voice=Pass\n",
      "формы          \tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      ",              \t_\n",
      "например       \tDegree=Pos\n",
      "\"              \t_\n",
      "стакан         \tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "\"              \t_\n",
      ",              \t_\n",
      "\"              \t_\n",
      "тройник        \tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "\"              \t_\n",
      "(              \t_\n",
      "элемент        \tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "трубопровода   \tAnimacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      ")              \t_\n",
      "или            \t_\n",
      "еще            \tDegree=Pos\n",
      "сложнее        \tDegree=Cmp\n",
      ".              \t_\n"
     ]
    }
   ],
   "source": [
    "for word, pos, gram in train[0]:\n",
    "    print('{:15}\\t{}'.format(word, gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammems = dict()\n",
    "pos_tags = set()\n",
    "words = set()\n",
    "for sentence in train:\n",
    "    for word, pos, gram in sentence:\n",
    "        words.add(word)\n",
    "        pos_tags.add(pos)\n",
    "        for pair in gram.split('|'):\n",
    "            if pair == '_':\n",
    "                continue\n",
    "            key = pair.split('=')[0]\n",
    "            value = pair.split('=')[1]\n",
    "            if not key in grammems:\n",
    "                grammems[key] = set()\n",
    "            grammems[key].add(value)\n",
    "            \n",
    "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
    "word2ind['<pad>'] = 0\n",
    "\n",
    "tag2ind = {tag: ind + 1 for ind, tag in enumerate(pos_tags)}\n",
    "tag2ind['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "gram2ind = {}\n",
    "gram2ind[('_','')] = 0\n",
    "for gram in grammems:\n",
    "    for value in grammems[gram]:\n",
    "        gram2ind[(gram, value)] = i\n",
    "        i += 1\n",
    "        \n",
    "gram_space = i\n",
    "gram_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtRbz1SwgEqc"
   },
   "outputs": [],
   "source": [
    "def convert_data(data, word2ind, tag2ind, gram2ind):\n",
    "    X = [[word2ind.get(word, 0) for word, pos, gram in sample] for sample in data]\n",
    "    y = [[tag2ind[tag] for word, tag, gram in sample] for sample in data]\n",
    "    gramms = []\n",
    "    for sample in data:\n",
    "        sentence = []\n",
    "        for word, pos, grams in sample:\n",
    "            vect = np.zeros(len(gram2ind))\n",
    "            for gram in grams.split('|'):\n",
    "                vect[gram2ind.get((gram.split('=')[0], gram.split('=')[-1]), 0)] = 1\n",
    "            sentence.append(vect)\n",
    "        gramms.append(sentence)\n",
    "    return X, y, np.array(gramms)\n",
    "\n",
    "X_train, y_train, g_train = convert_data(train, word2ind, tag2ind, gram2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhsTKZalfih6"
   },
   "outputs": [],
   "source": [
    "def iterate_batches(data, batch_size):\n",
    "    X, y, gramms = data\n",
    "    n_samples = len(X)\n",
    "\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_indices = indices[start:end]\n",
    "        \n",
    "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
    "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
    "        g_batch = np.zeros((max_sent_len, len(batch_indices), len(gramms[0][0])))\n",
    "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
    "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
    "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
    "            g_batch[:len(y[sample_ind]), batch_ind] = gramms[sample_ind]\n",
    "        yield X_batch, y_batch, g_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1088
    },
    "colab_type": "code",
    "id": "l4XsRII5kW5x",
    "outputId": "e19872bf-3f54-441d-ef7d-8cfbb0eb8387"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch, g_batch = next(iterate_batches((X_train, y_train, g_train), 4))\n",
    "\n",
    "g_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVEHju54d68T"
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, gramm_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._embs = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self._rnn = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
    "        self._tags = nn.Linear(lstm_layers_count*lstm_hidden_dim * 2, tagset_size)\n",
    "        self._gramms = nn.Sequential(\n",
    "            nn.Linear(tagset_size+lstm_layers_count*lstm_hidden_dim * 2, gramm_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self._embs(inputs)\n",
    "        \n",
    "        output, _ = self._rnn(emb)\n",
    "        pos = self._tags(output)\n",
    "        output = torch.cat((pos, output), -1)\n",
    "        return pos, self._gramms(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jbrxsZ2mehWB",
    "outputId": "aa039851-1eb7-404b-ce32-44a269b0b94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01666666753590107\n",
      "0.567375898361206\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind),\n",
    "    gramm_size=len(gram2ind)\n",
    ").cuda()\n",
    "\n",
    "X_batch, y_batch, g_batch = LongTensor(X_batch), LongTensor(y_batch), FloatTensor(g_batch)\n",
    "\n",
    "logits, gr_logits = model(X_batch)\n",
    "\n",
    "pos_preds = torch.argmax(logits, dim=-1)\n",
    "mask = (y_batch != 0).float()\n",
    "pos_correct_count = ((pos_preds == y_batch).float() * mask).sum()\n",
    "pos_total_score = (pos_correct_count / mask.sum()).item()\n",
    "print(pos_total_score)\n",
    "\n",
    "gr_preds = (gr_logits > 0.5).float()\n",
    "gr_correct_count = ((gr_preds == g_batch).float()).sum()\n",
    "gr_total_score = (gr_correct_count / (len(gr_preds)*gr_preds.shape[1]*gr_preds.shape[2])).item()\n",
    "print(gr_total_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sBBn9cBh5LqL",
    "outputId": "d77a4c89-3de0-4918-9b5b-c5b06ce66b63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9223, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_criterion = nn.CrossEntropyLoss()\n",
    "pos_criterion(logits.view(-1, logits.shape[-1]), y_batch.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2482, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_criterion = nn.MSELoss()\n",
    "gr_criterion(gr_logits, g_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FprPQ0gllo7b"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
    "    epoch_loss = 0\n",
    "    pos_correct_count = 0\n",
    "    pos_sum_count = 0\n",
    "    gr_correct_count = 0\n",
    "    gr_sum_count = 0\n",
    "    \n",
    "    pos_criterion, gr_criterion = criterion\n",
    "    is_train = not optimizer is None\n",
    "    name = name or ''\n",
    "    model.train(is_train)\n",
    "    \n",
    "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
    "    \n",
    "    with torch.autograd.set_grad_enabled(is_train):\n",
    "        with tqdm(total=batches_count) as progress_bar:\n",
    "            for i, (X_batch, y_batch, g_batch) in enumerate(iterate_batches(data, batch_size)):\n",
    "                X_batch, y_batch, g_batch = LongTensor(X_batch), LongTensor(y_batch), FloatTensor(g_batch)\n",
    "\n",
    "                logits, gr_logits = model(X_batch)\n",
    "                \n",
    "                pos_loss = pos_criterion(logits.view(-1, logits.shape[-1]), y_batch.view(-1))\n",
    "                gr_loss = gr_criterion(gr_logits, g_batch)\n",
    "                epoch_loss += gr_loss.item()\n",
    "\n",
    "                if optimizer:\n",
    "                    optimizer.zero_grad()\n",
    "                    pos_loss.backward(retain_graph=True)\n",
    "                    \n",
    "                    gr_loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                pos_preds = torch.argmax(logits, dim=-1)\n",
    "                mask = (y_batch != 0).float()\n",
    "                cur_pos_correct_count = ((pos_preds == y_batch).float() * mask).sum()\n",
    "                cur_pos_sum = mask.sum().item()\n",
    "                \n",
    "\n",
    "                gr_preds = (gr_logits > 0.5).float()\n",
    "                mask = ~((gr_preds == 0)*(g_batch == 0))\n",
    "                cur_gr_correct_count = (((gr_preds == g_batch)*mask).float()).sum()\n",
    "                cur_gr_sum = mask.sum().item()\n",
    "                \n",
    "                pos_correct_count += cur_pos_correct_count\n",
    "                pos_sum_count += cur_pos_sum\n",
    "                gr_correct_count += cur_gr_correct_count\n",
    "                gr_sum_count += cur_gr_sum\n",
    "\n",
    "                progress_bar.update()\n",
    "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PosAccuracy = {:.2%}, GrAccuracy = {:.2%}'.format(\n",
    "                    name, pos_loss.item(), cur_pos_correct_count / cur_pos_sum, cur_gr_correct_count/cur_gr_sum)\n",
    "                )\n",
    "                \n",
    "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PosAccuracy = {:.2%}, GrAccuracy = {:.2%}'.format(\n",
    "                name, epoch_loss / batches_count, pos_correct_count / pos_sum_count, gr_correct_count / gr_sum_count)\n",
    "            )\n",
    "\n",
    "    return epoch_loss / batches_count, pos_correct_count / pos_sum_count\n",
    "\n",
    "\n",
    "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
    "        val_data=None, val_batch_size=None):\n",
    "        \n",
    "    if not val_data is None and val_batch_size is None:\n",
    "        val_batch_size = batch_size\n",
    "        \n",
    "    for epoch in range(epochs_count):\n",
    "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
    "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
    "        \n",
    "        if not val_data is None:\n",
    "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2220
    },
    "colab_type": "code",
    "id": "Pqfbeh1ltEYa",
    "outputId": "b121f279-0bf9-4f3e-9731-dffab49f0631"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1 / 50] Train: Loss = 0.29528, PosAccuracy = 71.41%, GrAccuracy = 23.37%:  43%|██▏  | 327/753 [00:09<00:13, 32.43it/s]c:\\python36\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "[1 / 50] Train: Loss = 0.02222, PosAccuracy = 67.44%, GrAccuracy = 21.08%: 100%|█████| 753/753 [00:23<00:00, 32.66it/s]\n",
      "[2 / 50] Train: Loss = 0.01485, PosAccuracy = 85.99%, GrAccuracy = 36.28%: 100%|█████| 753/753 [00:22<00:00, 33.60it/s]\n",
      "[3 / 50] Train: Loss = 0.01344, PosAccuracy = 91.28%, GrAccuracy = 42.14%: 100%|█████| 753/753 [00:22<00:00, 33.48it/s]\n",
      "[4 / 50] Train: Loss = 0.01248, PosAccuracy = 94.22%, GrAccuracy = 46.12%: 100%|█████| 753/753 [00:22<00:00, 33.48it/s]\n",
      "[5 / 50] Train: Loss = 0.01180, PosAccuracy = 96.19%, GrAccuracy = 49.21%: 100%|█████| 753/753 [00:21<00:00, 34.64it/s]\n",
      "[6 / 50] Train: Loss = 0.01121, PosAccuracy = 97.53%, GrAccuracy = 51.73%: 100%|█████| 753/753 [00:22<00:00, 32.75it/s]\n",
      "[7 / 50] Train: Loss = 0.01078, PosAccuracy = 98.45%, GrAccuracy = 53.87%: 100%|█████| 753/753 [00:22<00:00, 33.04it/s]\n",
      "[8 / 50] Train: Loss = 0.01032, PosAccuracy = 99.03%, GrAccuracy = 55.91%: 100%|█████| 753/753 [00:22<00:00, 32.95it/s]\n",
      "[9 / 50] Train: Loss = 0.00979, PosAccuracy = 99.40%, GrAccuracy = 57.97%: 100%|█████| 753/753 [00:22<00:00, 32.85it/s]\n",
      "[10 / 50] Train: Loss = 0.00926, PosAccuracy = 99.64%, GrAccuracy = 60.17%: 100%|████| 753/753 [00:22<00:00, 33.15it/s]\n",
      "[11 / 50] Train: Loss = 0.00877, PosAccuracy = 99.78%, GrAccuracy = 62.60%: 100%|████| 753/753 [00:21<00:00, 34.35it/s]\n",
      "[12 / 50] Train: Loss = 0.00816, PosAccuracy = 99.87%, GrAccuracy = 65.38%: 100%|████| 753/753 [00:22<00:00, 32.98it/s]\n",
      "[13 / 50] Train: Loss = 0.00745, PosAccuracy = 99.92%, GrAccuracy = 68.40%: 100%|████| 753/753 [00:22<00:00, 32.88it/s]\n",
      "[14 / 50] Train: Loss = 0.00672, PosAccuracy = 99.95%, GrAccuracy = 71.57%: 100%|████| 753/753 [00:22<00:00, 34.00it/s]\n",
      "[15 / 50] Train: Loss = 0.00607, PosAccuracy = 99.97%, GrAccuracy = 74.72%: 100%|████| 753/753 [00:21<00:00, 34.26it/s]\n",
      "[16 / 50] Train: Loss = 0.00536, PosAccuracy = 99.96%, GrAccuracy = 77.60%: 100%|████| 753/753 [00:22<00:00, 33.85it/s]\n",
      "[17 / 50] Train: Loss = 0.00485, PosAccuracy = 99.96%, GrAccuracy = 79.83%: 100%|████| 753/753 [00:22<00:00, 33.99it/s]\n",
      "[18 / 50] Train: Loss = 0.00430, PosAccuracy = 99.99%, GrAccuracy = 82.45%: 100%|████| 753/753 [00:22<00:00, 33.92it/s]\n",
      "[19 / 50] Train: Loss = 0.00371, PosAccuracy = 99.99%, GrAccuracy = 84.94%: 100%|████| 753/753 [00:22<00:00, 33.18it/s]\n",
      "[20 / 50] Train: Loss = 0.00355, PosAccuracy = 99.93%, GrAccuracy = 85.56%: 100%|████| 753/753 [00:22<00:00, 33.20it/s]\n",
      "[21 / 50] Train: Loss = 0.00318, PosAccuracy = 99.98%, GrAccuracy = 87.09%: 100%|████| 753/753 [00:22<00:00, 32.91it/s]\n",
      "[22 / 50] Train: Loss = 0.00275, PosAccuracy = 99.99%, GrAccuracy = 89.02%: 100%|████| 753/753 [00:22<00:00, 33.01it/s]\n",
      "[23 / 50] Train: Loss = 0.00243, PosAccuracy = 100.00%, GrAccuracy = 90.51%: 100%|███| 753/753 [00:22<00:00, 32.87it/s]\n",
      "[24 / 50] Train: Loss = 0.00213, PosAccuracy = 100.00%, GrAccuracy = 91.77%: 100%|███| 753/753 [00:22<00:00, 32.76it/s]\n",
      "[25 / 50] Train: Loss = 0.00213, PosAccuracy = 99.93%, GrAccuracy = 91.61%: 100%|████| 753/753 [00:21<00:00, 34.31it/s]\n",
      "[26 / 50] Train: Loss = 0.00216, PosAccuracy = 99.95%, GrAccuracy = 91.30%: 100%|████| 753/753 [00:21<00:00, 34.45it/s]\n",
      "[27 / 50] Train: Loss = 0.00177, PosAccuracy = 100.00%, GrAccuracy = 93.17%: 100%|███| 753/753 [00:22<00:00, 33.56it/s]\n",
      "[28 / 50] Train: Loss = 0.00154, PosAccuracy = 100.00%, GrAccuracy = 94.18%: 100%|███| 753/753 [00:23<00:00, 32.73it/s]\n",
      "[29 / 50] Train: Loss = 0.00139, PosAccuracy = 100.00%, GrAccuracy = 94.82%: 100%|███| 753/753 [00:22<00:00, 32.39it/s]\n",
      "[30 / 50] Train: Loss = 0.00129, PosAccuracy = 100.00%, GrAccuracy = 95.22%: 100%|███| 753/753 [00:22<00:00, 33.79it/s]\n",
      "[31 / 50] Train: Loss = 0.00172, PosAccuracy = 99.90%, GrAccuracy = 92.93%: 100%|████| 753/753 [00:22<00:00, 33.66it/s]\n",
      "[32 / 50] Train: Loss = 0.00136, PosAccuracy = 99.99%, GrAccuracy = 94.72%: 100%|████| 753/753 [00:22<00:00, 33.17it/s]\n",
      "[33 / 50] Train: Loss = 0.00116, PosAccuracy = 100.00%, GrAccuracy = 95.70%: 100%|███| 753/753 [00:22<00:00, 34.11it/s]\n",
      "[34 / 50] Train: Loss = 0.00104, PosAccuracy = 100.00%, GrAccuracy = 96.20%: 100%|███| 753/753 [00:22<00:00, 34.16it/s]\n",
      "[35 / 50] Train: Loss = 0.00097, PosAccuracy = 100.00%, GrAccuracy = 96.52%: 100%|███| 753/753 [00:22<00:00, 33.63it/s]\n",
      "[36 / 50] Train: Loss = 0.00090, PosAccuracy = 100.00%, GrAccuracy = 96.73%: 100%|███| 753/753 [00:22<00:00, 33.96it/s]\n",
      "[37 / 50] Train: Loss = 0.00137, PosAccuracy = 99.92%, GrAccuracy = 94.40%: 100%|████| 753/753 [00:22<00:00, 33.60it/s]\n",
      "[38 / 50] Train: Loss = 0.00105, PosAccuracy = 99.99%, GrAccuracy = 95.94%: 100%|████| 753/753 [00:22<00:00, 33.64it/s]\n",
      "[39 / 50] Train: Loss = 0.00088, PosAccuracy = 100.00%, GrAccuracy = 96.76%: 100%|███| 753/753 [00:22<00:00, 33.21it/s]\n",
      "[40 / 50] Train: Loss = 0.00079, PosAccuracy = 100.00%, GrAccuracy = 97.13%: 100%|███| 753/753 [00:22<00:00, 33.21it/s]\n",
      "[41 / 50] Train: Loss = 0.00073, PosAccuracy = 100.00%, GrAccuracy = 97.35%: 100%|███| 753/753 [00:23<00:00, 32.55it/s]\n",
      "[42 / 50] Train: Loss = 0.00070, PosAccuracy = 100.00%, GrAccuracy = 97.51%: 100%|███| 753/753 [00:22<00:00, 33.12it/s]\n",
      "[43 / 50] Train: Loss = 0.00067, PosAccuracy = 100.00%, GrAccuracy = 97.62%: 100%|███| 753/753 [00:22<00:00, 33.62it/s]\n",
      "[44 / 50] Train: Loss = 0.00118, PosAccuracy = 99.92%, GrAccuracy = 95.07%: 100%|████| 753/753 [00:21<00:00, 34.38it/s]\n",
      "[45 / 50] Train: Loss = 0.00082, PosAccuracy = 99.99%, GrAccuracy = 96.86%: 100%|████| 753/753 [00:22<00:00, 33.63it/s]\n",
      "[46 / 50] Train: Loss = 0.00068, PosAccuracy = 100.00%, GrAccuracy = 97.52%: 100%|███| 753/753 [00:22<00:00, 33.88it/s]\n",
      "[47 / 50] Train: Loss = 0.00062, PosAccuracy = 100.00%, GrAccuracy = 97.79%: 100%|███| 753/753 [00:22<00:00, 33.95it/s]\n",
      "[48 / 50] Train: Loss = 0.00058, PosAccuracy = 100.00%, GrAccuracy = 97.92%: 100%|███| 753/753 [00:23<00:00, 32.50it/s]\n",
      "[49 / 50] Train: Loss = 0.00056, PosAccuracy = 100.00%, GrAccuracy = 98.02%: 100%|███| 753/753 [00:22<00:00, 32.87it/s]\n",
      "[50 / 50] Train: Loss = 0.00053, PosAccuracy = 100.00%, GrAccuracy = 98.10%: 100%|███| 753/753 [00:22<00:00, 33.40it/s]\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(\n",
    "    vocab_size=len(word2ind),\n",
    "    tagset_size=len(tag2ind),\n",
    "    gramm_size=len(gram2ind)\n",
    ").cuda()\n",
    "\n",
    "pos_criterion = nn.CrossEntropyLoss().cuda()\n",
    "gr_criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "fit(model, (pos_criterion, gr_criterion), optimizer, train_data=(X_train, y_train, g_train), epochs_count=50,\n",
    "    batch_size=64, val_data=None, val_batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_test_data(data, word2ind):\n",
    "    max_sent_len = max(len(data[ind]) for ind in range(len(data)))\n",
    "    X = np.zeros((max_sent_len, len(data)))\n",
    "    for i in range(len(data)):\n",
    "        X[:len(data[i]), i] = [word2ind.get(word, 0) for word in data[i]]\n",
    "    return X\n",
    "    \n",
    "X_test = convert_test_data(test, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 12380)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2tag = {tag2ind[key]:key for key in tag2ind}\n",
    "ind2tag[0] = '_'\n",
    "ind2gram = {gram2ind[key]:key for key in gram2ind}\n",
    "ind2gram[0] = ('_','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(pos, gr, ind2tag, ind2gram):\n",
    "    pos_str = ind2tag[pos]\n",
    "    if pos_str == '_':\n",
    "        return '_'\n",
    "    grams = []\n",
    "    for i, ind in enumerate(gr):\n",
    "        if ind != 0:\n",
    "            if ind2gram[i][0] == '_':\n",
    "                break\n",
    "            tmp = '='.join([ind2gram[i][0], ind2gram[i][1]])\n",
    "            grams.append(tmp)\n",
    "    if len(grams) == 0:\n",
    "        gr_str = '_'\n",
    "    else:\n",
    "        grams = np.sort(grams)\n",
    "        gr_str = '|'.join(grams)\n",
    "    return pos_str + '#' + gr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"submission.csv\", \"w\") as f:\n",
    "    f.write(\"Id,Prediction\\n\")\n",
    "    index = 0\n",
    "    size = X_test.shape[1]\n",
    "    offset = 0\n",
    "    while(offset < size):\n",
    "        part = np.min([50, size-offset])\n",
    "        \n",
    "        test_input = LongTensor(X_test[:, offset:offset+part])\n",
    "\n",
    "        model.eval()\n",
    "        logits, gr_logits = model(test_input)\n",
    "\n",
    "        pos_preds = torch.argmax(logits, dim=-1)\n",
    "        gr_preds = (gr_logits > 0.5).float()\n",
    "        for i in range(part):\n",
    "            for j in range(len(test[offset + i])):\n",
    "                f.write(\"%d,%s\\n\" % (index, get_tag(pos_preds[j, i].item(), gr_preds[j, i].cpu().detach().numpy(), ind2tag, ind2gram)))\n",
    "                index += 1\n",
    "        offset += part    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Week 06 - RNNs, part 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
